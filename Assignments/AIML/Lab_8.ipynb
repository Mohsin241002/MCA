{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab-8: Neural Network Implementation\n",
        "## Fuel Consumption Dataset Analysis and Prediction\n",
        "\n",
        "### Objectives:\n",
        "1. Load and perform EDA on the Fuel Consumption dataset\n",
        "2. Generate independent and dependent variables\n",
        "3. Encode categorical variables and split dataset\n",
        "4. Perform feature scaling using StandardScaler\n",
        "5. Initialize Artificial Neural Network with 2 hidden layers\n",
        "6. Create output layer and compile the network\n",
        "7. Train the neural network with specified parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries for Neural Network implementation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(\"TensorFlow Version:\", tf.__version__)\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Dataset and Perform EDA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the Fuel Consumption dataset\n",
        "df = pd.read_csv('Fuel_Consumption_2000-2022.csv')\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n",
        "print(\"\\nDataset Description:\")\n",
        "print(df.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(\"Missing Values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Check unique values in categorical columns\n",
        "categorical_columns = ['MAKE', 'VEHICLE CLASS', 'TRANSMISSION', 'FUEL']\n",
        "for col in categorical_columns:\n",
        "    print(f\"\\nUnique values in {col}: {df[col].nunique()}\")\n",
        "    print(f\"Sample values: {df[col].unique()[:10]}\")\n",
        "\n",
        "# Check data types\n",
        "print(\"\\nData Types:\")\n",
        "print(df.dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exploratory Data Analysis - Visualizations\n",
        "plt.figure(figsize=(15, 12))\n",
        "\n",
        "# 1. Distribution of target variable (EMISSIONS)\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.hist(df['EMISSIONS'], bins=50, alpha=0.7, color='skyblue')\n",
        "plt.title('Distribution of CO2 Emissions')\n",
        "plt.xlabel('CO2 Emissions (g/km)')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# 2. Fuel Consumption vs Emissions\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.scatter(df['FUEL CONSUMPTION'], df['EMISSIONS'], alpha=0.5)\n",
        "plt.title('Fuel Consumption vs CO2 Emissions')\n",
        "plt.xlabel('Fuel Consumption (L/100km)')\n",
        "plt.ylabel('CO2 Emissions (g/km)')\n",
        "\n",
        "# 3. Engine Size vs Emissions\n",
        "plt.subplot(2, 3, 3)\n",
        "plt.scatter(df['ENGINE SIZE'], df['EMISSIONS'], alpha=0.5, color='orange')\n",
        "plt.title('Engine Size vs CO2 Emissions')\n",
        "plt.xlabel('Engine Size (L)')\n",
        "plt.ylabel('CO2 Emissions (g/km)')\n",
        "\n",
        "# 4. Vehicle Class distribution\n",
        "plt.subplot(2, 3, 4)\n",
        "vehicle_counts = df['VEHICLE CLASS'].value_counts().head(10)\n",
        "plt.bar(range(len(vehicle_counts)), vehicle_counts.values)\n",
        "plt.title('Top 10 Vehicle Classes')\n",
        "plt.xticks(range(len(vehicle_counts)), vehicle_counts.index, rotation=45)\n",
        "plt.ylabel('Count')\n",
        "\n",
        "# 5. Fuel Type distribution\n",
        "plt.subplot(2, 3, 5)\n",
        "fuel_counts = df['FUEL'].value_counts()\n",
        "plt.pie(fuel_counts.values, labels=fuel_counts.index, autopct='%1.1f%%')\n",
        "plt.title('Fuel Type Distribution')\n",
        "\n",
        "# 6. Cylinders vs Emissions\n",
        "plt.subplot(2, 3, 6)\n",
        "cylinder_emissions = df.groupby('CYLINDERS')['EMISSIONS'].mean()\n",
        "plt.bar(cylinder_emissions.index, cylinder_emissions.values, color='green', alpha=0.7)\n",
        "plt.title('Average Emissions by Cylinders')\n",
        "plt.xlabel('Number of Cylinders')\n",
        "plt.ylabel('Average CO2 Emissions (g/km)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation analysis\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Select numerical columns for correlation\n",
        "numerical_cols = ['YEAR', 'ENGINE SIZE', 'CYLINDERS', 'FUEL CONSUMPTION', \n",
        "                  'HWY (L/100 km)', 'COMB (L/100 km)', 'COMB (mpg)', 'EMISSIONS']\n",
        "\n",
        "correlation_matrix = df[numerical_cols].corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
        "            square=True, linewidths=0.5)\n",
        "plt.title('Correlation Matrix of Numerical Features')\n",
        "plt.show()\n",
        "\n",
        "print(\"Correlation with EMISSIONS (target variable):\")\n",
        "print(correlation_matrix['EMISSIONS'].sort_values(ascending=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Generate Independent and Dependent Variables & Encode Categorical Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a copy of the dataset for preprocessing\n",
        "df_processed = df.copy()\n",
        "\n",
        "# Remove unnecessary columns (MODEL is too specific, keeping MAKE)\n",
        "columns_to_drop = ['MODEL']\n",
        "df_processed = df_processed.drop(columns=columns_to_drop)\n",
        "\n",
        "# Define target variable (dependent variable)\n",
        "target_column = 'EMISSIONS'\n",
        "y = df_processed[target_column].values\n",
        "\n",
        "print(f\"Target variable: {target_column}\")\n",
        "print(f\"Target variable shape: {y.shape}\")\n",
        "print(f\"Target variable statistics:\")\n",
        "print(f\"Mean: {y.mean():.2f}, Std: {y.std():.2f}, Min: {y.min():.2f}, Max: {y.max():.2f}\")\n",
        "\n",
        "# Define feature columns (independent variables)\n",
        "feature_columns = [col for col in df_processed.columns if col != target_column]\n",
        "print(f\"\\nFeature columns: {feature_columns}\")\n",
        "print(f\"Number of features: {len(feature_columns)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Encode categorical variables\n",
        "categorical_columns = ['MAKE', 'VEHICLE CLASS', 'TRANSMISSION', 'FUEL']\n",
        "label_encoders = {}\n",
        "\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    df_processed[col] = le.fit_transform(df_processed[col])\n",
        "    label_encoders[col] = le\n",
        "    print(f\"Encoded {col}: {len(le.classes_)} unique categories\")\n",
        "    print(f\"Sample original values: {le.classes_[:5]}\")\n",
        "    print(f\"Sample encoded values: {df_processed[col].unique()[:5]}\\n\")\n",
        "\n",
        "# Create feature matrix (independent variables)\n",
        "X = df_processed[feature_columns].values\n",
        "\n",
        "print(f\"Feature matrix shape: {X.shape}\")\n",
        "print(f\"Features after encoding:\")\n",
        "for i, col in enumerate(feature_columns):\n",
        "    print(f\"{i}: {col}\")\n",
        "\n",
        "# Display first few rows of processed data\n",
        "print(f\"\\nFirst 5 rows of processed features:\")\n",
        "print(pd.DataFrame(X[:5], columns=feature_columns))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
